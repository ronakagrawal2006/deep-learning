{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the steps we took to generate the Sequence Generatro for a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocess the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sample network with batches:\n",
    "# Steps:\n",
    "1. initialize global variables\n",
    "2. for each epoch e in epoch_range: --> output: epoch var\n",
    "        get the initial state of model --> output : model var : initial statel of model\n",
    "                                        --> initial state of model basicall the skeleton of lstm netowkr and state of cell initiailized with zeros.\n",
    "                                        -----> create method build_lstm() which returns lstm cell and initial state.\n",
    "                                        ----------> this will need RNNCell for hidden layers and batch size// need to check what impact batch_size has here. | output: hidden layer, batch_size\n",
    "                                        -----------> also given that we call this on lstm cell, we need to create that cell with basic dropout. | keep_prob, lstim_size\n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architechture has multiple comppenents :\n",
    "    1. input encoding\n",
    "    2. LSTM cells\n",
    "    3. RNN output with softmax\n",
    "    4 loss function,optimizer,\n",
    "    \n",
    "    \n",
    "    \n",
    "1. input encoding, need a mmethod to convert text to encoding.\n",
    "2 need a method to do batching and sequencing\n",
    "3. need a method to create the initial model\n",
    "4. \n",
    "\n",
    "\n",
    "the flow with shapes:\n",
    "    a. sequence * batches ---> eeach lstm cell. if sequence: \n",
    "    b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10         # Sequences per batch\n",
    "num_steps = 50          # Number of sequence steps per batch\n",
    "lstm_size = 128         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "# learning_rate = 0.01    # Learning rate\n",
    "keep_prob = 0.5         # Dropout keep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size,keep_prob):# this method returns the lstm layers, and initial state\n",
    "    basic_lstm=tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(basic_lstm,output_keep_prob=keep_prob)\n",
    "    cell=tf.contrib.rnn.MultiRNNCell([drop] *num_layers)\n",
    "    initial_state=cell.zero_state(batch_size,tf.float32)\n",
    "    return cell, initial_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(dtype=tf.int32,shape=(batch_size,num_steps),name='inputs')\n",
    "    targets = tf.placeholder(dtype=tf.int32,shape=(batch_size,num_steps),name='targets')\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(dtype=tf.float32,shape=(),name='keep_prob')\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    def __init__(self,lstm_size=128,num_layers=2,batch_size=64):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.inputs, self.targets,self.keep_prob=build_inputs(batch_size,num_steps)\n",
    "        cell, self.initial_state=build_lstm(lstm_size,num_layers,batch_size,keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = CharRNN(lstm_size,num_layers,batch_size,keep_prob)\n",
    "epochs=2\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    counter=0 #dont know why added\n",
    "    for e in range(epochs):\n",
    "        new_state=sess.run(model.initial_state)# why do we need new_State?\n",
    "        loss=0 # why loss???\n",
    "        for x,y in get_batches(encoded,batch_size,num_steps) : # here you need to feed batches of inputs\n",
    "            counter+=1\n",
    "            start=time.time()\n",
    "            feed={\n",
    "                model.inputs:x,\n",
    "                model.targets:y,\n",
    "                model.keep_prob: keep_prob,\n",
    "                model.initial_state=new_state\n",
    "            }\n",
    "            batch_loss,new_state,_=sess.run([model.loss,model.final_state,model.optimizer],feed_dict=feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=np.arange(0,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets= np.arange(1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 12)\n"
     ]
    }
   ],
   "source": [
    "print(range(0,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, inputs):\n",
    "        pass\n",
    "    \n",
    "    tf.reset_default_graph() # why do we need this\n",
    "    \n",
    "    self.inputs= tf.placeholder(tf.float32,shape=(2,3),name='inputs')\n",
    "    self.targets= tf.placeholder(tf.float32,shape=(2,3),name='targets')\n",
    "    self.cells= tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(5)] * 2) \n",
    "    self.lstm_initial_state= cells.zero_state(2,tf.float32) # need to understand why this needs batches size as input\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hell, tensor sucks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hello_constant= tf.constant(\"hell, tensor sucks\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(hello_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_var= tf.constant(2)\n",
    "second_var= tf.constant(3)\n",
    "addittion=tf.add(first_var,second_var)\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(addittion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.3]\n"
     ]
    }
   ],
   "source": [
    "#placeholders usage, more like paramteres without ref\n",
    "\n",
    "first_var= tf.placeholder(tf.float32,shape=(),name=\"first_var\")\n",
    "second_var= tf.placeholder(tf.float32,shape=(),name=\"second_var\")\n",
    "addittion=tf.add(first_var,second_var)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    add = sess.run([addittion],feed_dict={first_var:2.1,second_var:3.2})\n",
    "    print(add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside custom method doing shit!\n",
      "[5.3]\n"
     ]
    }
   ],
   "source": [
    "def my_add(a,b):\n",
    "    print(\"inside custom method doing shit!\")\n",
    "    return a+b\n",
    "first_var= tf.placeholder(tf.float32,shape=(),name=\"first_var\")\n",
    "second_var= tf.placeholder(tf.float32,shape=(),name=\"second_var\")\n",
    "addittion=my_add(first_var,second_var)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    add = sess.run([addittion],feed_dict={first_var:2.1,second_var:3.2})\n",
    "    print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer():\n",
    "    \n",
    "    return optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to define the graph and cells here:\n",
    "batch_size=2\n",
    "step_size=3\n",
    "inputs=tf.placeholder(tf.int32,shape(batch_size,step_size),name='inputs') #place holder defnintion\n",
    "targets=tf.placeholder(tf.int32,shape(batch_size,step_size),name='targets')\n",
    "\n",
    "inputs_value=np.arage(0,12)\n",
    "targets_value=np.arage(1,13)\n",
    "\n",
    "feed={\n",
    "    inputs:inputs_value,\n",
    "    targets:targets_value\n",
    "}\n",
    "\n",
    "loss=None # loss unction\n",
    "optimizer=None #some optimizer\n",
    "model = None # basicall some fucntion that takes input and generates ouput\n",
    "with tf.Session as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple lstm model\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # assuming that we have variables.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "Initialize global variables\n",
    "put feed in session.run?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
